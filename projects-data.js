const projects = [
  {
    "id": "forge",
    "name": "FORGE",
    "tagline": "Federated Orchestration & Resource Generation Engine",
    "description": [
      "FORGE represents a paradigm shift in AI-powered development workflows. As an intelligent control panel for autonomous coding agents, it provides a unified interface for managing complex multi-agent orchestration, resource allocation, and federated task distribution. Unlike single-agent tools that limit you to one AI assistant at a time, FORGE orchestrates entire teams of specialized agents working in concert.",
      "At its core, FORGE solves the challenge of coordinating multiple AI agents working on different aspects of a software project simultaneously. It handles context management, prevents conflicting changes, and ensures that agents have access to the right resources at the right time. The system implements sophisticated scheduling algorithms that optimize for both speed and code quality, dynamically load-balancing tasks across available agents based on their current workload and specialization.",
      "One of FORGE's most powerful features is its multi-platform agent support. The system seamlessly integrates with Claude Code, OpenCode, Aider, Goose, and other popular autonomous coding frameworks. Each agent can be paired with different language models‚Äîfrom Anthropic's Claude to OpenAI's GPT-4, DeepSeek, GLM-4, and more. This flexibility allows teams to optimize for cost, capability, and specialized domain knowledge. A complex refactoring task might be assigned to Claude Code with Anthropic's Opus, while routine test generation goes to OpenCode with a more cost-effective model.",
      "The architecture employs a hub-and-spoke model where FORGE acts as the central orchestrator, maintaining a shared context pool that all agents can access. When Agent A modifies a file, FORGE immediately propagates that change to Agent B's context if they're working on related code. This prevents the classic multi-agent problem of conflicting edits and ensures consistency across the entire codebase. The system uses sophisticated diff algorithms and conflict detection to identify potential issues before they occur, automatically resolving simple conflicts and escalating complex ones for human review.",
      "Resource management is handled through an intelligent quota system. FORGE tracks token usage, API rate limits, and cost metrics across all agents and models. If you're approaching your API quota, the system automatically scales back non-critical tasks or switches to more economical models. This prevents unexpected bills and ensures critical work always has the resources it needs. The platform provides real-time cost analytics, showing exactly how much each agent operation costs and helping teams optimize their AI development budget.",
      "The real-time monitoring dashboard gives complete visibility into what every agent is doing. You can see which files are being modified, what prompts are being sent, token consumption rates, and success metrics for each task. When an agent encounters an error or gets stuck, FORGE's automatic recovery system kicks in‚Äîretrying with different prompts, switching to a different model, or breaking the task into smaller subtasks. This resilience is crucial for production environments where autonomous agents need to operate reliably without constant human supervision.",
      "FORGE excels at intelligent task decomposition and allocation. When you feed it a high-level objective like 'add user authentication to the web app,' it breaks this down into concrete subtasks: database schema changes, API endpoint creation, frontend forms, session management, security testing, and documentation updates. Each subtask is then assigned to the most appropriate agent based on the agent's specialization, current workload, and the estimated complexity. The system can parallelize independent tasks‚Äîone agent working on backend auth while another builds the login UI‚Äîdramatically reducing overall completion time.",
      "Integration with existing development workflows is seamless. FORGE connects to your Git repository, CI/CD pipelines, issue trackers, and project management tools. When a GitHub issue is created, FORGE can automatically spawn an agent to investigate and propose a fix. When a pull request fails CI tests, an agent can analyze the failure, fix the issue, and resubmit. The system respects your development standards, running code formatters, linters, and test suites before committing any changes. It can even write commit messages that match your team's conventions.",
      "Security and compliance are built into the core architecture. FORGE implements role-based access control, ensuring agents can only modify files and access resources they're authorized for. All agent interactions are logged with full audit trails, making it easy to understand what changed, when, and why. For regulated industries, FORGE can enforce compliance policies‚Äîrequiring human review for certain types of changes, preventing modifications to critical infrastructure, or ensuring all code meets specific quality gates before deployment.",
      "The platform's scalability is proven in production environments managing dozens of concurrent agents. Whether you're a solo developer using FORGE to coordinate three agents on a side project, or an enterprise team orchestrating fifty agents across multiple microservices, the system scales gracefully. The distributed architecture can run on a single laptop or scale across cloud infrastructure for enterprise deployments. FORGE's event-driven design ensures minimal latency‚Äîagents receive task assignments and context updates in milliseconds.",
      "Looking forward, FORGE is evolving toward fully autonomous development operations. The vision is a system where you can assign high-level business objectives‚Äî'build a customer analytics dashboard' or 'optimize database performance by 50%'‚Äîand FORGE coordinates entire teams of specialized agents to research, design, implement, test, and deploy the solution. With continuous learning from past tasks, the system gets better at estimating effort, choosing the right models for each job, and preventing common pitfalls. This represents the future of software development: humans focusing on product vision and architecture while AI agents handle the implementation details at unprecedented scale and speed."
    ],
    "tech": [
      "Python",
      "AI Orchestration",
      "Distributed Systems",
      "Task Management"
    ],
    "github": "https://github.com/jedarden/forge",
    "demo": null,
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                    <rect x=\"40\" y=\"60\" width=\"120\" height=\"100\" rx=\"8\" fill=\"#8B1A1A\" opacity=\"0.9\"/>\n                    <rect x=\"60\" y=\"80\" width=\"30\" height=\"30\" rx=\"4\" fill=\"white\"/>\n                    <rect x=\"110\" y=\"80\" width=\"30\" height=\"30\" rx=\"4\" fill=\"white\"/>\n                    <rect x=\"60\" y=\"120\" width=\"80\" height=\"8\" rx=\"4\" fill=\"white\"/>\n                    <rect x=\"60\" y=\"135\" width=\"60\" height=\"8\" rx=\"4\" fill=\"white\"/>\n                    <circle cx=\"150\" cy=\"50\" r=\"15\" fill=\"#B8534E\"/>\n                    <path d=\"M145 45 L155 50 L145 55\" stroke=\"white\" stroke-width=\"3\" fill=\"none\"/>\n                </svg>",
    "visual": "<div class=\"project-visual visual-forge\">\n                            <div class=\"forge-pipes\">\n                                <div class=\"pipe pipe-1\"><div class=\"data-flow\"></div></div>\n                                <div class=\"pipe pipe-2\"><div class=\"data-flow\"></div></div>\n                                <div class=\"pipe pipe-3\"><div class=\"data-flow\"></div></div>\n                                <div class=\"pipe pipe-4\"><div class=\"data-flow\"></div></div>\n                                <div class=\"pipe pipe-5\"><div class=\"data-flow\"></div></div>\n                                <div class=\"pipe pipe-6\"><div class=\"data-flow\"></div></div>\n                            </div>\n                            <div class=\"agent-combo agent-1\"><span class=\"agent-name\">Claude Code</span><span class=\"model-name\">Anthropic</span></div>\n                            <div class=\"agent-combo agent-2\"><span class=\"agent-name\">OpenCode</span><span class=\"model-name\">OpenAI</span></div>\n                            <div class=\"agent-combo agent-3\"><span class=\"agent-name\">Claude Code</span><span class=\"model-name\">GLM-4</span></div>\n                            <div class=\"agent-combo agent-4\"><span class=\"agent-name\">Goose</span><span class=\"model-name\">GLM-4</span></div>\n                            <div class=\"agent-combo agent-5\"><span class=\"agent-name\">OpenCode</span><span class=\"model-name\">DeepSeek</span></div>\n                            <div class=\"agent-combo agent-6\"><span class=\"agent-name\">Aider</span><span class=\"model-name\">Anthropic</span></div>\n                            <div class=\"control-center\"><div class=\"forge-label\">FORGE</div><div class=\"forge-subtitle\">Multi-Agent<br/>Orchestrator</div></div>\n                        </div>",
    "tldr": "FORGE orchestrates multiple AI coding agents simultaneously‚ÄîClaude Code, Aider, Goose, and more‚Äîeach paired with different LLMs. It handles context sharing, prevents conflicts, and optimizes resource allocation so teams of specialized agents can work in concert on complex software projects."
  },
  {
    "id": "options",
    "name": "Options Trading",
    "tagline": "Options Analytics & Strategy Platform",
    "description": [
      "A sophisticated options trading analytics platform that provides real-time market data analysis, volatility surface visualization, and advanced options pricing models. The system aggregates data from multiple exchanges, calculates Greeks (Delta, Gamma, Theta, Vega, Rho), and identifies profitable trading opportunities through machine learning pattern recognition. Designed for serious options traders who need institutional-grade analytics without institutional-level costs, the platform processes complex calculations in milliseconds to keep pace with fast-moving options markets.",
      "## Advanced Pricing Models",
      "The platform implements multiple pricing frameworks to handle different option types and market conditions. Black-Scholes modeling provides theoretical valuations for European-style options, incorporating risk-free rates, implied volatility, time to expiration, and underlying price movements. Binomial tree models handle American-style options with early exercise features, simulating price paths through a tree of possible outcomes and working backward to determine optimal exercise strategies. Monte Carlo simulation capabilities model complex options with path-dependent payoffs, averaging across thousands of simulated price trajectories to estimate fair value.",
      "Adjustments for real-world complications include dividend payment modeling that accounts for ex-dividend dates and estimates their impact on option prices, volatility smile fitting that captures the market's actual pricing of different strikes rather than assuming flat volatility, and interest rate term structure integration that uses appropriate rates for different expiration periods. These refinements ensure pricing accuracy matches real market conditions, not just textbook assumptions.",
      "The Greeks calculation engine computes sensitivities for entire portfolios, not just individual positions. Delta measures directional exposure, showing how much the portfolio value changes with $1 moves in the underlying. Gamma tracks delta's rate of change, critical for understanding risks in dynamic hedging strategies. Theta quantifies time decay, showing daily profit/loss from passage of time alone. Vega measures volatility exposure, essential for volatility arbitrage strategies. Rho captures interest rate sensitivity, increasingly important in varying rate environments.",
      "## Volatility Surface Analysis",
      "Interactive volatility smile charts visualize how implied volatility varies across strikes and expirations, revealing market expectations about future price distributions. The smile shape indicates whether the market expects larger moves than log-normal distributions predict (steep wings), is pricing in tail risks (skew toward puts), or anticipates potential jumps (term structure inversion). Traders use these patterns to identify mispricings, construct volatility arbitrage strategies, and understand market sentiment.",
      "The platform fits volatility surfaces using industry-standard models (SABR, SVI), smoothing noisy market data into continuous functions that can be interpolated for any strike/expiration combination. This enables accurate pricing of exotic options, comparison of implied versus historical volatility across the entire surface, and detection of arbitrage opportunities where market prices violate fundamental no-arbitrage relationships.",
      "Historical volatility analysis compares realized price movements against implied volatility predictions, identifying periods when options consistently overpriced or underpriced upcoming volatility. This mean-reversion insight drives profitable strategies like selling premium when IV is elevated relative to HV, or buying protection when markets underestimate impending volatility spikes.",
      "## Strategy Identification and Optimization",
      "Automated spread strategy identification scans current market prices to find optimal entry points for common strategies. The system suggests iron condors when IV is high and the underlying is range-bound, identifies undervalued calendar spreads when term structure is inverted, recommends butterflies when volatility clustering creates favorable risk/reward ratios, and highlights ratio spreads when skew patterns suggest directional mispricings.",
      "For each suggested strategy, the platform provides detailed analysis including maximum profit and loss scenarios across a range of underlying prices, breakeven points marking where the strategy transitions between profit and loss, probability of profit based on implied volatility distributions, and Greeks exposure showing how the position's sensitivity evolves as market conditions change. This comprehensive view enables informed decision-making beyond simple premium collection.",
      "Position optimization tools help construct portfolios with specific risk profiles. Want delta-neutral exposure to profit from volatility changes alone? The system calculates hedge ratios. Need to reduce gamma to avoid being whipsawed by price oscillations? It suggests adjustment trades. Trying to maximize theta decay while limiting downside risk? It proposes specific strike selections and position sizing.",
      "## Risk Management Framework",
      "Portfolio Greeks analysis aggregates exposure across all positions, showing total delta, gamma, theta, vega, and rho for the entire portfolio. Visual dashboard displays indicate when exposures exceed risk limits, highlighting potential vulnerabilities before they become problems. The system tracks correlation risks where seemingly hedged positions might move together during market stress, and monitors concentration risks where too much capital is committed to similar strategies or underlyings.",
      "Maximum loss calculations simulate worst-case scenarios, stress testing portfolios against extreme market moves like gap-downs past stop-loss levels, volatility explosions that blow out short premium positions, or pin risk where underlying settles exactly at a short strike. These scenarios, modeled with appropriate probability distributions, help size positions so that even tail events remain manageable.",
      "Margin requirement estimations integrate with broker margin models (Reg T, portfolio margin, SPAN), showing capital requirements for proposed positions before trades are executed. The system warns when adding positions would trigger margin calls, suggests capital-efficient alternatives that achieve similar exposure with lower margin requirements, and tracks buying power utilization to prevent over-leveraging.",
      "## Real-Time Market Monitoring",
      "The platform processes thousands of options contracts per second, streaming quotes from exchanges and updating analytics in real-time. Data aggregation combines feeds from CBOE, ISE, NASDAQ, and other venues to find best prices, identify unusual trading activity like block trades or sweep orders, and detect liquidity imbalances that might signal informed trading.",
      "Customizable alerts monitor for unusual options activity like abnormally high volume in specific strikes suggesting informed traders positioning for events, significant open interest changes indicating institutional accumulation or unwinding, and volatility spikes that may precede major price moves. Earnings plays are automatically identified based on straddle pricing around announcement dates, historical earnings move magnitudes, and current implied volatility versus past earnings cycles.",
      "## Backtesting and Performance Analytics",
      "The backtesting engine validates strategies against years of historical options data, simulating realistic fills using historical bid-ask spreads, incorporating slippage and commission costs, and accounting for early assignment risks on short American options. Results show how strategies performed across different market regimes‚Äîbull markets, bear markets, high volatility periods, low volatility grinds‚Äîrevealing whether profits depend on specific conditions or represent robust edges.",
      "Performance attribution breaks down returns into components: profit from directional moves (delta), profit from volatility changes (vega), time decay capture (theta), and gamma scalping gains. This analysis reveals strategy drivers, helping traders double down on what works and eliminate what doesn't. Sharpe ratios, maximum drawdowns, and win rates provide standard metrics for comparing strategies and tracking live performance against backtested expectations."
    ],
    "tech": [
      "Python",
      "React",
      "WebSockets",
      "Financial Models"
    ],
    "github": null,
    "demo": "https://options.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <path d=\"M30 150 L50 120 L70 130 L90 90 L110 100 L130 60 L150 70 L170 40\"\n                      stroke=\"#8B1A1A\" stroke-width=\"3\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\"/>\n                <path d=\"M30 150 L50 140 L70 145 L90 130 L110 135 L130 120 L150 125 L170 110\"\n                      stroke=\"#A52A2A\" stroke-width=\"2\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" opacity=\"0.6\"/>\n                <circle cx=\"130\" cy=\"60\" r=\"6\" fill=\"#B8534E\"/>\n                <rect x=\"25\" y=\"155\" width=\"150\" height=\"2\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <rect x=\"28\" y=\"30\" width=\"2\" height=\"127\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <text x=\"140\" y=\"50\" font-family=\"monospace\" font-size=\"14\" fill=\"#8B1A1A\" font-weight=\"bold\">‚Üë</text>\n            </svg>",
    "visual": "<div class=\"project-visual visual-options\"><div class=\"chart-container\"><svg class=\"chart-svg\" viewBox=\"0 0 400 200\"><path class=\"chart-path\" d=\"M0 150 Q50 120, 100 100 T200 80 T300 60 T400 90\" fill=\"none\" stroke=\"#8B1A1A\" stroke-width=\"3\"/></svg><div class=\"chart-marble\"></div></div></div>",
    "tldr": "An options analytics platform that calculates Greeks, visualizes volatility surfaces, identifies optimal spread strategies, and stress-tests positions against extreme scenarios. Built for traders who need clear insights into pricing dynamics and risk exposure."
  },
  {
    "id": "newstrading",
    "name": "News Trading",
    "tagline": "AI-Powered News Sentiment Trading",
    "description": [
      "An automated trading system that leverages natural language processing to analyze breaking news, social media sentiment, and financial reports in real-time, executing trades based on market-moving information before it's fully priced in. The system monitors thousands of news sources across multiple languages and time zones, filters for relevance using trained classifiers, and employs transformer-based language models to assess sentiment and likely market impact with millisecond-level latency. In markets where information asymmetry drives alpha, being first to interpret and act on news provides a measurable edge.",
      "## Multi-Source Data Ingestion",
      "The platform ingests news from diverse sources to build comprehensive market intelligence. RSS feeds from major financial news outlets (Bloomberg, Reuters, WSJ) provide professional journalism with credibility signals. Twitter/X monitoring captures retail sentiment and tracks social media influencers whose posts move markets. Financial APIs like Alpha Vantage and IEX Cloud supply structured data about earnings, dividends, and corporate events. Press release services (PR Newswire, Business Wire) deliver company announcements the moment they're published. SEC EDGAR filings capture regulatory disclosures like 8-Ks, 13-Fs, and insider trading reports.",
      "Each source requires different parsing strategies: Twitter needs real-time streaming and handles rate limits while filtering out noise. RSS feeds use polling with smart deduplication to avoid processing the same story multiple times. API integrations handle pagination, authentication, and retry logic for reliable data flow. EDGAR scraping navigates HTML forms and extracts structured data from PDF documents using specialized parsers.",
      "The aggregation pipeline normalizes data from heterogeneous sources into a unified format, timestamps each event precisely for latency tracking, deduplicates stories reported by multiple outlets, and prioritizes based on source credibility and historical predictive value. This curated feed ensures the NLP models process high-signal data without being overwhelmed by redundant or irrelevant noise.",
      "## Natural Language Processing Pipeline",
      "Processing each article through multiple NLP models creates a multi-dimensional understanding of market-moving information. Named Entity Recognition (NER) extracts relevant entities including publicly traded companies with ticker symbol resolution, executive names for management change stories, geographic locations for region-specific events, and products or drugs for FDA approval or recall news. Entity linking disambiguates mentions (is 'Apple' the tech company or the fruit?) using context-aware models.",
      "Sentiment classification employs fine-tuned BERT and RoBERTa transformers trained specifically on financial texts, where language conventions differ from general-purpose corpora. The models classify sentiment as positive, negative, or neutral with granular confidence scores, detect nuanced tones like cautious optimism or defensive denial, and identify hedging language that might indicate uncertainty or downplaying risks. Multi-label classification captures mixed sentiment‚Äîlike positive earnings but disappointing guidance‚Äîwhich single-label systems miss.",
      "Market impact estimation uses machine learning models trained on historical news-price correlations. Features include sentiment polarity and strength, source credibility (Bloomberg terminal > random blog), entity prominence (CEO resignation > middle manager departure), timing relative to market hours, and story velocity (how quickly it's spreading). The model outputs probability distributions over expected price movements, enabling the system to size positions proportionally to conviction and potential magnitude.",
      "## Historical Correlation Engine",
      "The system maintains a comprehensive database correlating past news events with subsequent price movements, allowing it to learn which types of news reliably move markets and which are noise. For earnings announcements, it tracks surprise magnitude (actual vs. consensus), post-announcement drift patterns, and whether beats or misses in specific line items (revenue vs. EPS) drive stronger reactions. This enables the system to quickly interpret current earnings reports by comparing to historical patterns.",
      "FDA approval news is analyzed based on drug indication, market size, competitive landscape, and previous trials' success rates. The system knows that Phase 3 trial results move biotech stocks more than Phase 1 results, that orphan drug designations have different implications than me-too medications, and that certain therapeutic areas command higher valuations than others. This domain knowledge, learned from thousands of examples, enables nuanced interpretation beyond simple positive/negative classification.",
      "Geopolitical events are challenging because each one is somewhat unique, but the system still extracts useful patterns. Trade war escalations tend to hurt exporters while benefiting domestic producers. Energy price spikes affect airlines, logistics companies, and manufacturers differently. Currency fluctuations from central bank announcements impact multinationals with significant foreign revenue. By clustering similar historical events and analyzing their market impacts, the system develops playbooks for responding to new geopolitical developments.",
      "## Trade Execution Strategy",
      "Execution speed is critical‚Äîthe system aims to trade within milliseconds of significant news breaking, before algorithmic competitors and before manual traders can react. Direct market access connections to exchanges minimize latency. Pre-computed position sizes for different confidence levels eliminate calculation delays. Limit orders are placed slightly away from market price to ensure fills while avoiding adverse selection from toxic order flow.",
      "Position sizing scales with conviction derived from model confidence scores, historical prediction accuracy for similar events, and current market volatility levels. High-confidence, high-impact news justifies larger positions, while speculative signals warrant smaller probes. The system never risks more than 2% of capital on a single trade regardless of confidence, implementing strict per-trade risk limits that prevent catastrophic losses from any single mistake.",
      "Trade timing considerations include avoiding thinly traded hours when bid-ask spreads widen and slippage increases, scaling into positions over multiple minutes if the news suggests a sustained move rather than immediate spike, and using options instead of shares when implied volatility is low relative to expected price movement magnitude. The system dynamically chooses execution tactics based on current market microstructure conditions.",
      "## Comprehensive Risk Management",
      "Risk management is paramount in a strategy where reaction speed can sometimes outpace comprehension. The system includes automatic stop-losses at predefined levels based on position size and volatility, never letting winners turn into losers by trailing stops as positions move favorably, and closing positions if news interpretation is contradicted by price action (suggesting the market disagrees with the NLP's assessment). These mechanical rules prevent emotional decision-making and limit drawdowns.",
      "Exposure limits constrain risk across multiple dimensions: maximum capital allocated to news trading overall, limits per news category (earnings, M&A, FDA, geopolitical), limits per sector to avoid concentration risk, and limits on correlated positions that might move together during market stress. The system rejects profitable-looking trades if they would violate exposure limits, prioritizing capital preservation over maximum returns.",
      "Circuit breakers halt trading during unusual market conditions including flash crashes or limit-up/down moves, extraordinary volatility spikes that suggest broken markets, abnormal spreads indicating liquidity problems, and situations where the NLP model's confidence collapses (suggesting input data quality issues). These safeguards prevent the system from trading when conditions fall outside its training distribution.",
      "## Performance Analytics and Monitoring",
      "Backtesting validates the strategy across various market regimes, testing on data the models never saw during training to avoid overfitting. The system shows strong performance around binary events like earnings announcements where reactions are directional and meaningful, FDA approvals/rejections where outcomes are clear-cut, and merger arbitrage where deal spreads respond predictably to news. Performance is weaker on ambiguous geopolitical developments where market reactions are context-dependent and hard to predict.",
      "The real-time dashboard provides comprehensive monitoring showing incoming news feed with sentiment scores and market impact estimates, active positions with current P&L and stop-loss levels, recent trades with entry rationale and outcome, aggregate performance metrics including win rate, average winner/loser, Sharpe ratio, and maximum drawdown, and anomaly alerts highlighting unusual patterns that might indicate model degradation or market regime change.",
      "Attribution analysis decomposes returns into components: alpha from news interpretation skill, alpha from execution speed advantages, beta exposure during sustained directional trends, luck from binary outcomes (where being right had significant randomness), and costs from slippage, commissions, and adverse selection. This breakdown reveals whether profits come from genuine edge or simply from being long in a bull market, guiding strategy refinements and risk adjustments."
    ],
    "tech": [
      "Python",
      "NLP",
      "Transformers",
      "Trading Algorithms"
    ],
    "github": null,
    "demo": "https://news-trading.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <rect x=\"40\" y=\"50\" width=\"120\" height=\"100\" rx=\"4\" fill=\"none\" stroke=\"#8B1A1A\" stroke-width=\"3\"/>\n                <rect x=\"50\" y=\"65\" width=\"50\" height=\"3\" fill=\"#A52A2A\"/>\n                <rect x=\"50\" y=\"75\" width=\"40\" height=\"3\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <rect x=\"50\" y=\"82\" width=\"45\" height=\"3\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <rect x=\"110\" y=\"65\" width=\"40\" height=\"25\" fill=\"#B8534E\" opacity=\"0.3\"/>\n                <path d=\"M115 95 L125 110 L135 100 L145 115\" stroke=\"#8B1A1A\" stroke-width=\"2\" fill=\"none\"/>\n                <rect x=\"50\" y=\"100\" width=\"50\" height=\"3\" fill=\"#A52A2A\"/>\n                <rect x=\"50\" y=\"110\" width=\"40\" height=\"3\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <rect x=\"50\" y=\"117\" width=\"35\" height=\"3\" fill=\"#1D1D1F\" opacity=\"0.3\"/>\n                <circle cx=\"165\" cy=\"45\" r=\"8\" fill=\"#B8534E\"/>\n                <text x=\"161\" y=\"50\" font-family=\"monospace\" font-size=\"12\" fill=\"white\" font-weight=\"bold\">!</text>\n            </svg>",
    "visual": "<div class=\"project-visual visual-newstrading\">\n                            <div class=\"news-ticker\">üì∞ Breaking: Tech Stock Soars +15%</div>\n                            <div class=\"news-ticker\">üìà Market Alert: Fed Announcement</div>\n                            <div class=\"news-ticker\">üíπ Earnings Beat Expectations</div>\n                        </div>",
    "tldr": "AI-powered sentiment analysis that processes news feeds, extracting trading ideas from earnings reports, Fed announcements, and social media. Generates actionable insights based on sentiment scores, helping traders identify opportunities before they become obvious."
  },
  {
    "id": "ducke",
    "name": "DUCK-E",
    "tagline": "The Duck That Talks Back",
    "description": [
      "DUCK-E revolutionizes the venerable practice of rubber duck debugging by transforming it from a one-way monologue into an intelligent, interactive conversation. Using OpenAI's groundbreaking Realtime API, DUCK-E doesn't just listen‚Äîit asks probing questions, suggests alternative approaches, and actively helps you think through complex problems in real-time with voice-native interaction. The difference between talking to a silent rubber duck and conversing with DUCK-E is like the difference between thinking alone and pair programming with a senior engineer who has infinite patience and encyclopedic knowledge.",
      "## Voice-First Debugging",
      "The system processes your voice in real-time using OpenAI's Realtime API, achieving sub-200ms latency from when you stop speaking to when DUCK-E starts responding. This natural conversation flow eliminates the cognitive overhead of typing, allowing you to verbalize thoughts as they form without breaking your mental model of the problem. The voice interface captures vocal cues like uncertainty in your tone, pace of speaking that indicates confused or confident understanding, and emotional state that might indicate frustration or breakthrough moments.",
      "DUCK-E's verbal responses are synthesized with natural prosody and inflection, asking clarifying questions with appropriate rising intonation, emphasizing key insights to ensure they land, and varying pace based on complexity‚Äîslowing down for complex explanations, speeding up for simple confirmations. The voice interaction feels genuinely conversational, not robotic, making extended debugging sessions feel less isolating than the typical solo debugging grind.",
      "The conversation memory maintains context throughout long debugging sessions, remembering earlier hypotheses you've ruled out, tracking which approaches have been tried and failed, and referencing previous parts of the conversation naturally. DUCK-E might say 'Earlier you mentioned the auth middleware, and I'm wondering if that could be related to the timeout you're seeing now'‚Äîdemonstrating genuine continuity that would be tedious to maintain through text chat's scroll history.",
      "## Multi-Agent Collaborative Debugging",
      "The system leverages the AutoGen framework to implement sophisticated multi-agent conversations where specialized debugging agents collaborate. The Code Analysis Agent focuses on understanding syntax, control flow, and code structure, identifying potential bugs, code smells, and anti-patterns, and suggesting refactorings for clarity or performance. The Systems Agent understands distributed systems, networking, and infrastructure, reasoning about race conditions, concurrency bugs, and resource contention, helping diagnose cross-service communication failures and database deadlocks.",
      "The Domain Expert Agent adapts to your problem domain, loading relevant context for web development, mobile apps, data science, or other specialties, and applying domain-specific debugging heuristics like 'check CORS headers for cross-origin issues' in web dev or 'verify data types match database schema' for backend bugs. The Test Strategy Agent suggests test cases that would reproduce the bug, proposes unit tests to prevent regressions, and helps design integration tests for complex interactions.",
      "These agents don't just work in parallel‚Äîthey genuinely collaborate. When you describe a bug, they might have an internal debate (which you can optionally overhear) where the Code Agent suggests a syntax issue, the Systems Agent counters that it's probably a timeout, and they reason through which hypothesis better fits your symptoms. This multi-perspective analysis often catches nuances that a single agent would miss.",
      "## Interactive Problem-Solving",
      "DUCK-E can analyze stack traces you read aloud or paste, walking through the call stack from error site back to origin, explaining what each frame represents in plain language, and identifying the likely culprit based on error type and stack structure. It helps you understand not just where the error occurred but why, building deeper debugging skills through explanation.",
      "Code review capabilities let you read code snippets aloud (or paste them for longer sections), and DUCK-E provides real-time feedback identifying potential bugs, suggesting improvements, and explaining why certain patterns are problematic. The system understands code across languages‚ÄîPython, JavaScript, Java, Go, Rust‚Äîadapting its suggestions to language-specific idioms and best practices.",
      "Scenario simulation helps you reason through edge cases by describing hypothetical inputs or states. DUCK-E mentally traces execution paths, identifies where different code branches lead, and predicts outcomes without requiring you to actually run the code. This 'desk check' capability helps catch bugs before they make it into your test suite. For race conditions or timing-dependent bugs, DUCK-E can describe different interleavings of concurrent operations, helping you visualize how threads might interfere with each other.",
      "## Adaptive Expertise Levels",
      "The system adapts its questioning style and explanations based on your expertise level and the problem domain. For beginners, it explains fundamental concepts without jargon, suggests googling resources for deeper learning, and provides more directive guidance ('Try adding a print statement here to see the variable value'). For experienced developers, it assumes knowledge of design patterns and architecture, engages in higher-level discussions about tradeoffs, and asks challenging questions that make you think deeper ('Have you considered what happens if this runs under heavy load?').",
      "Domain adaptation occurs dynamically as the conversation reveals your problem space. If you mention async/await, DUCK-E knows you're working in a language with asynchronous programming and adjusts accordingly. If you describe React components, it shifts to frontend debugging patterns. If you mention SQL joins, it pivots to database query optimization knowledge. This contextual awareness prevents irrelevant suggestions and keeps the conversation focused.",
      "The questioning strategy varies by problem complexity: for simple bugs, DUCK-E asks direct diagnostic questions ('What's the error message?'). For complex architectural issues, it employs Socratic method, asking questions that lead you to discover the answer yourself‚Äîwhich research shows leads to better understanding than being told the solution. For exploratory debugging where the root cause is unknown, it guides you through systematic elimination processes.",
      "## IDE Integration and Context Awareness",
      "The system integrates with popular IDEs (VS Code, JetBrains IDEs, Vim/Neovim), allowing it to access file paths and line numbers, see the currently open file without you reading it aloud, access error messages from integrated terminals, and understand workspace structure and file relationships. This contextual awareness means you can say 'the bug is in the file I'm looking at' rather than spelling out '/src/components/Header.tsx'‚ÄîDUCK-E already knows.",
      "Documentation access on the fly means DUCK-E can query official docs for libraries you're using, reference API documentation without you leaving your editor, and cite specific sections of documentation when suggesting solutions. If you're struggling with a complex API, DUCK-E can pull up examples and explain them in the context of your specific use case, bridging the gap between generic documentation and your specific problem.",
      "The workspace understanding includes awareness of your project structure (monorepo vs. single project, frontend vs. backend directories), familiarity with your configuration files (.eslintrc, tsconfig.json, package.json), and knowledge of your dependencies and their versions. This context prevents suggestions like 'use this newer API' when you're locked to an older version, or recommending libraries you don't have installed.",
      "## Structured Debugging Protocols",
      "Beyond conversational guidance, DUCK-E provides structured debugging protocols for systematic problem-solving. The Scientific Method Protocol guides you through forming hypotheses, designing experiments to test them, interpreting results, and refining theories. This prevents random 'shotgun debugging' where you change things without understanding why. The Binary Search Protocol helps narrow down the bug's location by systematically dividing the problem space, testing midpoints to determine which half contains the bug, and repeating until the exact location is found.",
      "The Rubber Duck 2.0 Protocol combines the benefits of explaining to a duck (forcing you to articulate your assumptions) with active listening where DUCK-E interrupts if your explanation contains logical inconsistencies, asks for clarification on vague statements, and highlights assumptions that might be wrong. This catches errors in reasoning that you'd skip over when talking to an inanimate duck.",
      "## Real-World Debugging Benefits",
      "The practical impact is measurable: developers report reducing median time-to-fix from hours to minutes for complex bugs, catching logical errors during the 'explaining to DUCK-E' phase before even running tests, and building better debugging intuition through repeated guided problem-solving. The system is particularly valuable for solo developers who lack teammates for rubber ducking, late-night debugging sessions when no one else is available, and onboarding junior developers who need guidance without monopolizing senior engineers' time.",
      "Specific success stories include tracking down a subtle race condition in a microservices architecture by talking through request flows with DUCK-E, identifying a CSS specificity issue causing intermittent styling problems through systematic rule elimination guided by DUCK-E, and debugging a memory leak in a Python service by having DUCK-E suggest profiling strategies and interpret the results. The common thread is that DUCK-E provides not just answers but a collaborative debugging partner who helps you think more clearly about complex problems."
    ],
    "tech": [
      "OpenAI Realtime",
      "FastAPI",
      "AutoGen",
      "Voice AI",
      "Real-time Processing"
    ],
    "github": "https://github.com/jedarden/duck-e",
    "demo": null,
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <ellipse cx=\"100\" cy=\"130\" rx=\"45\" ry=\"35\" fill=\"#FFD93D\"/>\n                <circle cx=\"100\" cy=\"75\" r=\"38\" fill=\"#FFD93D\"/>\n                <ellipse cx=\"88\" cy=\"70\" rx=\"6\" ry=\"8\" fill=\"#1D1D1F\"/>\n                <ellipse cx=\"112\" cy=\"70\" rx=\"6\" ry=\"8\" fill=\"#1D1D1F\"/>\n                <ellipse cx=\"89\" cy=\"68\" rx=\"2\" ry=\"3\" fill=\"white\"/>\n                <ellipse cx=\"113\" cy=\"68\" rx=\"2\" ry=\"3\" fill=\"white\"/>\n                <ellipse cx=\"100\" cy=\"88\" rx=\"12\" ry=\"8\" fill=\"#F4A020\"/>\n                <ellipse cx=\"100\" cy=\"86\" rx=\"8\" ry=\"4\" fill=\"#E8941C\"/>\n                <ellipse cx=\"55\" cy=\"120\" rx=\"18\" ry=\"12\" fill=\"#FFD93D\"/>\n                <ellipse cx=\"145\" cy=\"120\" rx=\"18\" ry=\"12\" fill=\"#FFD93D\"/>\n                <circle cx=\"70\" cy=\"55\" r=\"12\" fill=\"#FFD93D\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-ducke\"><div class=\"ducke-container\"><div class=\"voice-input\"><div class=\"mic-icon\">üé§</div><div class=\"sound-waves input-waves\"><div class=\"wave wave-1\"></div><div class=\"wave wave-2\"></div><div class=\"wave wave-3\"></div></div></div><div class=\"ducke-center\"><div class=\"spaghetti-code\"><svg class=\"spaghetti-svg\" viewBox=\"0 0 100 100\"><path class=\"noodle noodle-1\" d=\"M10 20 Q30 40, 50 20 T90 30\" /><path class=\"noodle noodle-2\" d=\"M15 50 Q35 30, 55 50 T95 45\" /><path class=\"noodle noodle-3\" d=\"M5 70 Q40 90, 60 70 T100 80\" /></svg></div><div class=\"duck-bubble\"><span class=\"duck-icon\">ü¶Ü</span></div><div class=\"thought-bubbles\"><div class=\"thought thought-1\">üêõ</div><div class=\"thought thought-2\">üí°</div><div class=\"thought thought-3\">‚úì</div></div></div><div class=\"voice-output\"><div class=\"sound-waves output-waves\"><div class=\"wave wave-1\"></div><div class=\"wave wave-2\"></div><div class=\"wave wave-3\"></div></div><div class=\"speaker-icon\">üîä</div></div><div class=\"ducke-label\">Speech ‚Üí Debug ‚Üí Speech</div></div></div>",
    "tldr": "Voice-first rubber duck debugging that actually talks back. Describe your bug out loud and DUCK-E asks clarifying questions, suggests hypotheses, and guides you through systematic debugging‚Äîlike pair programming with an AI that never gets tired of listening."
  },
  {
    "id": "clasp",
    "name": "CLASP",
    "tagline": "Claude Language Agent Super Proxy",
    "description": [
      "CLASP breaks down the walls between AI coding platforms by acting as a universal translation layer that enables Claude Code workflows to run seamlessly with any LLM provider. It's the bridge that connects best-in-class development tools with the flexibility of choosing your preferred language model, whether for cost optimization, capability requirements, or simply avoiding vendor lock-in. In an ecosystem where AI coding tools are often tightly coupled to specific providers, CLASP provides the freedom to use the right model for each task without sacrificing your preferred tooling.",
      "## Universal API Translation",
      "The proxy intelligently translates API calls between different provider formats, converting Anthropic's message structure to OpenAI's chat completion format, mapping Claude's system prompts to provider-specific equivalents, and transforming tool/function calling syntax across different schemas. This isn't simple passthrough‚ÄîCLASP understands the semantic meaning of each API element and translates it preserving intent rather than just structure.",
      "Provider-specific quirks are handled transparently: some providers paginate long responses while others stream them as single chunks, rate limit structures vary from per-minute tokens to per-day requests, error codes and formats differ across providers, and retry/backoff strategies need provider-specific tuning. CLASP abstracts all these differences behind a consistent interface, so your code doesn't need to know which provider is backing each request.",
      "Authentication management supports multiple credential types including API keys for services like OpenAI, Anthropic, Cohere, OAuth flows for enterprise Azure OpenAI deployments, custom headers for self-hosted model servers, and session tokens for providers with more complex auth patterns. CLASP rotates credentials automatically when approaching rate limits, securely stores credentials outside of application code, and validates permissions before routing requests to ensure credentials have appropriate scopes.",
      "## Advanced Feature Support",
      "CLASP supports the full feature set that modern AI coding workflows require. Streaming responses work identically across all providers‚Äîeven those that don't natively support streaming‚Äîby buffering and chunking complete responses to simulate streams. This ensures your UI can display progress and provide responsive feedback regardless of the underlying model's streaming support.",
      "Function calling translation is particularly sophisticated since every provider implements tool usage differently. Anthropic's tool syntax differs from OpenAI's function calling, which differs from open-source frameworks' agent tool formats. CLASP normalizes these into a single schema your code uses, then translates to the provider's specific format. It handles the full function calling flow: describing available functions in the provider's schema format, parsing function call requests from model responses, executing functions through your defined callbacks, and returning results in the expected format for multi-turn function calling conversations.",
      "Multi-turn conversations present challenges since conversation formats vary (message arrays vs. single strings, role naming differences, context window tracking). CLASP maintains conversation state efficiently across turns, automatically managing context windows by trimming old messages when approaching limits, preserving critical system prompts and recent context, and using provider-specific strategies like Claude's conversation continuation or GPT's max_tokens to ensure long conversations remain coherent.",
      "## Intelligent Routing and Fallback",
      "The routing engine selects optimal providers based on multiple criteria including model capability requirements (does this task need function calling? reasoning? multimodal understanding?), cost constraints and budgets, latency requirements (some providers have faster inference), availability and rate limit status, and historical performance for similar queries. This dynamic routing ensures each request uses the best available model for its specific needs.",
      "Automatic fallback handling provides resilience when primary providers fail. If a request to OpenAI times out, CLASP can automatically retry with Anthropic. If you hit rate limits on your preferred provider, it seamlessly switches to a backup. If a specific model is temporarily unavailable, it routes to a similar-capability alternative. This happens transparently without application code needing error handling for every possible provider failure mode.",
      "Fallback strategies are configurable: strict mode ensures all fallbacks use models with identical capabilities even if more expensive, cost-optimized mode prioritizes cheaper alternatives even if slightly less capable, and balanced mode weighs both capability and cost. You can define custom fallback chains specifying exactly which models to try in sequence, with different chains for different task types.",
      "## Cost Optimization",
      "Built-in cost optimization tracks usage across all providers, showing real-time and historical spending by provider, model, project, or time period. The system alerts when spending approaches budget limits, provides cost projections based on current usage patterns, and identifies opportunities to reduce costs by switching models for specific workloads.",
      "Model selection intelligence automatically routes prompts to the cheapest model capable of handling them. Simple code completion requests use lightweight models like GPT-3.5 or Claude Haiku. Complex reasoning tasks requiring chain-of-thought upgrade to GPT-4 or Claude Opus. The system learns from past successes and failures, building a profile of which models work well for which types of requests, and continuously optimizes the cost-performance tradeoff.",
      "Caching strategies reduce redundant API calls by identifying identical or similar prompts and reusing recent responses, implementing semantic caching that matches prompts with similar meaning even if worded differently, respecting TTL constraints to avoid serving stale responses, and invalidating cache when underlying code or context changes. Smart caching can reduce API costs by 40-60% for applications with repeated queries.",
      "## Performance Analytics",
      "Detailed analytics provide visibility into model performance and usage patterns. Latency tracking measures time-to-first-token and total generation time across providers, identifying performance bottlenecks and comparing provider speeds for different request types. Quality metrics track task success rates, user satisfaction signals, and retry frequencies to identify models that struggle with specific tasks.",
      "Usage dashboards visualize request volumes over time, token consumption patterns, cost trends and anomalies, error rates by provider and model type, and cache hit rates and savings. These insights guide infrastructure decisions like which provider contracts to negotiate, which models to deprecate from rotation, and where caching investments yield highest returns.",
      "The analytics engine supports custom metrics and dimensions, allowing teams to track domain-specific quality indicators, correlate model choices with downstream application metrics, and perform cohort analysis on model performance across user segments. Exportable reports integrate with business intelligence tools for cross-functional analysis.",
      "## Development and Production Use",
      "For development teams, CLASP enables experimentation without rewriting code. Want to test if GPT-4 Turbo handles your use case better than Claude Opus? Just update the routing config. Curious about open-source model performance? Point CLASP at a self-hosted Llama instance. Evaluating a new provider like Cohere or AI21? Add their credentials and route traffic. The abstraction layer means experimenting with new models is a configuration change, not a code refactor.",
      "Production deployments benefit from CLASP's reliability features including automatic retry logic with exponential backoff, circuit breakers that stop routing to failing providers, health checks that preemptively avoid unhealthy backends, and graceful degradation that serves cached or default responses when all providers are unavailable. These patterns keep applications running even when AI providers experience outages.",
      "Multi-region support allows routing to geographically closer provider endpoints for reduced latency, complying with data residency requirements by choosing region-appropriate providers, and load balancing across regions for high-availability deployments. This global infrastructure awareness makes CLASP suitable for worldwide applications with diverse latency and compliance needs."
    ],
    "tech": [
      "Python",
      "LLM Proxy",
      "Multi-Provider",
      "API Gateway"
    ],
    "github": "https://github.com/jedarden/CLASP",
    "demo": null,
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <rect x=\"30\" y=\"80\" width=\"60\" height=\"40\" rx=\"6\" fill=\"#8B1A1A\"/>\n                <rect x=\"110\" y=\"80\" width=\"60\" height=\"40\" rx=\"6\" fill=\"#A52A2A\"/>\n                <path d=\"M90 100 L110 100\" stroke=\"#B8534E\" stroke-width=\"6\" stroke-linecap=\"round\"/>\n                <circle cx=\"90\" cy=\"100\" r=\"8\" fill=\"#B8534E\"/>\n                <circle cx=\"110\" cy=\"100\" r=\"8\" fill=\"#B8534E\"/>\n                <text x=\"50\" y=\"105\" font-family=\"monospace\" font-size=\"16\" fill=\"white\" font-weight=\"bold\">AI</text>\n                <text x=\"127\" y=\"105\" font-family=\"monospace\" font-size=\"16\" fill=\"white\" font-weight=\"bold\">LLM</text>\n            </svg>",
    "visual": "<div class=\"project-visual visual-clasp\">\n                            <div class=\"clasp-source\">\n                                <div class=\"provider-badge anthropic\">Claude Code</div>\n                            </div>\n                            <div class=\"clasp-connector\">\n                                <div class=\"api-packet packet-1\"></div>\n                                <div class=\"api-packet packet-2\"></div>\n                            </div>\n                            <div class=\"clasp-hub\">\n                                <div class=\"hub-ring\"></div>\n                                <div class=\"hub-core\">CLASP</div>\n                            </div>\n                            <div class=\"clasp-outputs\">\n                                <div class=\"output-line line-1\"><div class=\"api-packet packet-out\"></div></div>\n                                <div class=\"output-line line-2\"><div class=\"api-packet packet-out\"></div></div>\n                                <div class=\"output-line line-3\"><div class=\"api-packet packet-out\"></div></div>\n                            </div>\n                            <div class=\"clasp-targets\">\n                                <div class=\"provider-badge openai\">OpenAI</div>\n                                <div class=\"provider-badge azure\">Azure</div>\n                                <div class=\"provider-badge ollama\">Ollama</div>\n                            </div>\n                        </div>",
    "tldr": "A proxy that adapts Claude Code tool calls to work with non-Anthropic APIs like OpenAI, Azure, and Ollama. Write once using Claude Code's format, then route to any provider with automatic translation, fallback, and cost tracking."
  },
  {
    "id": "mana",
    "name": "MANA",
    "tagline": "Memory-Augmented Neural Assistant",
    "description": [
      "MANA represents the cutting edge of context management for AI coding agents, implementing an adaptive learning system that intelligently manages and retrieves contextual information across long-running development sessions. It solves the critical challenge of maintaining relevant context as projects grow beyond what fits in a single prompt window‚Äîthe fundamental limitation that caps how much AI agents can accomplish in one session. While current LLMs have context windows measured in hundreds of thousands of tokens, large codebases easily exceed these limits, and MANA provides the memory architecture that makes long-term autonomous development feasible.",
      "## Intelligent Context Retrieval",
      "Using advanced RAG (Retrieval-Augmented Generation) techniques, MANA builds a dynamic knowledge graph of your codebase that goes beyond simple file indexing. The system identifies architectural patterns like microservices boundaries, API contracts between services, and data flow patterns. It tracks important conventions like naming patterns, error handling strategies, and testing approaches. It captures implicit knowledge like 'files in /utils are stateless helpers' or 'the AuthService is a singleton'‚Äîpatterns that experienced developers know but aren't documented anywhere.",
      "The knowledge graph represents code as a network of relationships: imports/dependencies between files, function call graphs showing who calls what, data flow showing how information moves through the system, and conceptual relationships like 'these three files all implement different caching strategies.' This rich representation enables queries like 'find code related to user authentication' that understand semantic relationships beyond keyword matching.",
      "Automatic pattern recognition identifies recurring structures that indicate significance. Frequently modified files are probably core to the application. Functions with many callers are important API boundaries. Configuration files that many modules import are centralized control points. MANA weights context importance based on these signals, ensuring retrieval surfaces critical information before peripheral details.",
      "## Adaptive Learning and Relevance",
      "The system learns which context is most valuable for different types of tasks through feedback loops. When an agent successfully completes a task, MANA analyzes which context was retrieved and used, reinforcing those retrieval patterns for similar future tasks. When tasks fail or require multiple iterations, MANA identifies what context was missing and adjusts retrieval strategies to surface that information earlier next time.",
      "Task-type specialization means MANA builds different context profiles for different work: bug fixes need stack traces, error logs, and recently changed files; new feature development needs architectural diagrams, similar existing features, and API documentation; refactoring tasks need test suites, dependent code, and performance metrics. The retrieval engine automatically detects task types from agent prompts and queries and adjusts its strategy accordingly.",
      "Proactive context surfacing anticipates information needs before agents explicitly request it. If an agent is modifying an API endpoint, MANA preemptively retrieves the frontend code that calls that endpoint, test suites covering that functionality, and documentation describing the API contract. This reduces the number of retrieval round-trips needed and keeps agents from going down unproductive paths due to missing context.",
      "## Semantic Search and Chunking",
      "The semantic search implementation goes far beyond grep or simple keyword matching. It uses embedding models to represent code semantically‚Äîfunctions that accomplish similar goals map to similar vectors even if they use completely different variable names or syntax. Queries like 'find code that validates user input' match relevant functions across the codebase regardless of whether they're named validate_input, check_user_data, or sanitize_form_submission.",
      "Intelligent chunking strategies preserve meaningful context boundaries rather than arbitrarily splitting on character counts. The system chunks at natural boundaries including complete function definitions, class definitions, logical sections within files marked by comments, and related imports/dependencies that provide necessary context. This ensures retrieved chunks are self-contained and understandable without needing to fetch adjacent code to make sense of them.",
      "Cross-reference resolution enhances chunks by including relevant references: if a chunk references an interface defined elsewhere, MANA includes that interface definition; if it calls helper functions, it includes their signatures; if it uses constants, it includes their values. This automatic augmentation means agents receive coherent, complete context without needing to issue cascading retrieval queries.",
      "## Temporal Context Management",
      "MANA tracks relevance decay over time through sophisticated temporal models. Recency matters‚Äîcode changed yesterday is more relevant than code untouched for months. Access frequency matters‚Äîinformation retrieved often is probably important. But simple recency isn't enough: a configuration file changed six months ago might still be critical if it's accessed frequently. MANA weighs multiple temporal signals to determine what stays in active memory versus what gets archived.",
      "Automatic archiving moves outdated context to cold storage while keeping metadata searchable. Archived content doesn't pollute retrieval results but remains accessible if explicitly needed. The archiving policy is configurable: aggressive archiving maximizes relevance but might miss edge cases; conservative archiving keeps more context active but increases noise. The sweet spot varies by project‚ÄîMANA's default adaptive policy learns from usage patterns.",
      "Context versioning tracks how information changes over time. If code structure was refactored, MANA knows both the old and new patterns. If an API was deprecated and replaced, it understands the migration path. This temporal awareness prevents confusion when agents encounter older code that uses deprecated patterns‚ÄîMANA can provide context like 'this uses the legacy auth pattern that was replaced in v2.0.'",
      "## Integration with AI Development Tools",
      "MANA integrates seamlessly with Claude Code and other AI development tools, providing a persistent memory layer that survives session boundaries. When you start a new Claude Code session, MANA provides context from previous sessions including what was accomplished, what problems were encountered, decisions that were made, and open questions or TODOs. This continuity enables multi-day autonomous development projects where each session builds on previous work without starting from scratch.",
      "The integration works through standardized interfaces: context retrieval APIs that agents call with semantic queries, automatic context injection that MANA pushes proactively, feedback loops where agents signal what context was useful, and configuration hooks for tuning retrieval strategies. The API is provider-agnostic‚Äîit works equally well with Claude Code, Cursor, Copilot Workspace, or custom agent frameworks.",
      "Performance optimization ensures retrieval operations complete in <100ms even for large codebases. Vector similarity search uses approximate nearest neighbor indexes (FAISS, Annoy) that trade perfect accuracy for speed. Caching layers store frequently accessed context in memory. Parallel retrieval queries can fetch multiple chunks simultaneously. These optimizations keep MANA responsive even when indexing hundreds of thousands of files.",
      "## Codebase Understanding",
      "Beyond simple text retrieval, MANA builds genuine understanding of codebase structure and semantics. It parses code into ASTs (Abstract Syntax Trees) to understand structure beyond text, runs static analysis to find dependencies and call graphs, executes symbol resolution to understand what identifiers refer to, and performs type inference to track data flow. This deep analysis enables queries that keyword search couldn't handle, like 'find all places where this function might throw an exception' or 'show me code paths that lead to this database query.'",
      "Language-agnostic architecture supports polyglot codebases through language-specific parsers (tree-sitter, LSP integration) and shared semantic representations. Whether your codebase mixes Python, JavaScript, Go, and SQL or is monoglot, MANA provides consistent indexing and retrieval. The cross-language understanding knows that a REST API endpoint in Python is called by frontend JavaScript and stores data in PostgreSQL‚Äîrelationships that span language boundaries.",
      "The system handles not just code but also documentation in Markdown, READMEs, and code comments; configuration in YAML, JSON, and TOML; infrastructure as code (Terraform, Kubernetes manifests); database schemas and migration files; and test files and fixtures. This comprehensive indexing means agents can find relevant context across the entire project, not just source code.",
      "## Privacy and Security",
      "MANA is designed with privacy as a core principle. All code indexing and embedding happens locally or in your private infrastructure‚Äîcode never leaves your control to be processed by third-party embedding services unless you explicitly choose that. The vector database can run entirely on-premises or in your private cloud. This makes MANA suitable for sensitive codebases including proprietary code, work under NDA, regulated industries with data residency requirements, and open-source projects that value contributor privacy.",
      "Security features include access control integration with your existing auth systems, audit logging of all context retrievals, encryption at rest for stored embeddings and metadata, and isolation between projects preventing cross-contamination. Multi-tenant deployments support org-level separation where different teams' code remains isolated, and project-level separation within teams where certain codebases have restricted access.",
      "## Scalability and Performance",
      "The system scales from small personal projects to massive enterprise monorepos. For small codebases (<10K files), MANA runs entirely in memory with near-instant retrieval. For medium codebases (<100K files), disk-backed indexes maintain fast performance. For huge codebases (>100K files), distributed indexing and sharding spread the load across multiple machines. The largest MANA deployment indexes over 1 million files across 50 microservices, serving retrieval queries to hundreds of AI agents with P99 latency under 200ms.",
      "Incremental updates keep indexes fresh without full rebuilds. When files change, MANA re-indexes only affected files and updates dependency graphs incrementally. This enables real-time indexing where changes appear in search results within seconds. The update strategy is eventually consistent‚Äîqueries might briefly return slightly stale results, but the index converges quickly to the current state.",
      "## Future Vision",
      "The roadmap for MANA includes conversational context where the memory system tracks not just code but the reasoning and decisions captured in agent-human conversations, creating an institutional memory of why things were done certain ways. Active learning where MANA suggests documentation for under-documented areas or identifies code that seems inconsistent with established patterns. Cross-project learning where patterns and solutions from one project inform context retrieval in another‚Äîorganizational knowledge transfer encoded in the memory system.",
      "With MANA, your AI agents truly remember everything that matters and forget everything that doesn't, enabling autonomous development that spans days, weeks, or months rather than being limited to single sessions. The persistent, intelligent memory transforms AI coding assistants from tools you use for discrete tasks into genuine collaborators that build deep understanding of your codebase over time."
    ],
    "tech": [
      "Python",
      "RAG",
      "Vector DB",
      "Context Management"
    ],
    "github": "https://github.com/jedarden/MANA",
    "demo": null,
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <circle cx=\"100\" cy=\"100\" r=\"45\" fill=\"none\" stroke=\"#8B1A1A\" stroke-width=\"3\"/>\n                <circle cx=\"70\" cy=\"80\" r=\"12\" fill=\"#A52A2A\"/>\n                <circle cx=\"130\" cy=\"80\" r=\"12\" fill=\"#A52A2A\"/>\n                <circle cx=\"70\" cy=\"120\" r=\"12\" fill=\"#A52A2A\"/>\n                <circle cx=\"130\" cy=\"120\" r=\"12\" fill=\"#A52A2A\"/>\n                <circle cx=\"100\" cy=\"100\" r=\"15\" fill=\"#B8534E\"/>\n                <line x1=\"100\" y1=\"100\" x2=\"70\" y2=\"80\" stroke=\"#8B1A1A\" stroke-width=\"2\"/>\n                <line x1=\"100\" y1=\"100\" x2=\"130\" y2=\"80\" stroke=\"#8B1A1A\" stroke-width=\"2\"/>\n                <line x1=\"100\" y1=\"100\" x2=\"70\" y2=\"120\" stroke=\"#8B1A1A\" stroke-width=\"2\"/>\n                <line x1=\"100\" y1=\"100\" x2=\"130\" y2=\"120\" stroke=\"#8B1A1A\" stroke-width=\"2\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-mana\"><div class=\"mana-container\"><div class=\"context-label top\">Codebase Context</div><div class=\"mana-connections\"><svg><line class=\"connection-line\" x1=\"150\" y1=\"50\" x2=\"110\" y2=\"130\"/><line class=\"connection-line\" x1=\"60\" y1=\"80\" x2=\"110\" y2=\"130\"/><line class=\"connection-line\" x1=\"240\" y1=\"80\" x2=\"190\" y2=\"130\"/><line class=\"connection-line\" x1=\"30\" y1=\"160\" x2=\"110\" y2=\"170\"/><line class=\"connection-line\" x1=\"270\" y1=\"160\" x2=\"190\" y2=\"170\"/></svg></div><div class=\"knowledge-node node-1\">API</div><div class=\"knowledge-node node-2\">DB</div><div class=\"knowledge-node node-3\">Auth</div><div class=\"knowledge-node node-4\">Test</div><div class=\"knowledge-node node-5\">Cfg</div><div class=\"vector-ring\"><div class=\"vector-dot\"></div><div class=\"vector-dot\"></div><div class=\"vector-dot\"></div><div class=\"vector-dot\"></div></div><div class=\"rag-core\"><span class=\"rag-label\">RAG</span><span class=\"rag-sublabel\">Memory</span></div><div class=\"memory-indicator\"><div class=\"memory-block\"></div><div class=\"memory-block\"></div><div class=\"memory-block\"></div><div class=\"memory-block\"></div><div class=\"memory-block\"></div></div></div></div>",
    "tldr": "Intelligent context management for AI coding agents using RAG and knowledge graphs. MANA remembers your codebase structure, tracks what worked in past sessions, and proactively surfaces relevant context so agents can work effectively across long development projects."
  },
  {
    "id": "ccdash",
    "name": "CCDash",
    "tagline": "Lightweight TUI Dashboard",
    "description": [
      "CCDash brings the elegance of modern web dashboards to the terminal, creating a beautiful, efficient monitoring solution for developers who live and breathe the command line. It provides comprehensive visibility into system resources, Claude Code token consumption, and tmux session management‚Äîall in a sleek terminal interface that feels native to your workflow. For terminal-native developers who consider switching to a browser a context-switch tax, CCDash brings production-grade monitoring into your environment of choice.",
      "## Real-Time System Monitoring",
      "The dashboard features real-time graphs of CPU, memory, and network usage with customizable refresh rates (0.5s to 60s intervals) and multiple color themes (nord, dracula, solarized, custom). CPU graphs show per-core utilization with sparklines for trend visualization, highlight processes consuming excessive resources, and track temperature sensors on supported hardware. Memory monitoring displays RAM usage broken down by process, tracks swap usage and page fault rates, and alerts when approaching OOM conditions before they cause crashes.",
      "Network monitoring captures bandwidth usage on all interfaces, showing download/upload rates with historical trends, tracking packet loss and error rates, and identifying which processes are consuming bandwidth. The connection table displays active network connections with remote hosts, ports, and protocols, helping identify unexpected connections or bandwidth hogs. For remote development, CCDash shows SSH session counts and helps diagnose network-related slowdowns.",
      "Disk I/O monitoring tracks read/write operations per second, displays which processes are causing disk thrashing, shows filesystem capacity and inode usage, and alerts on low disk space before it impacts development work. The system uptime tracker includes load averages (1min, 5min, 15min), displays system boot time and recent reboots, and tracks service restarts and crashes. This comprehensive view prevents performance mysteries from interrupting your flow.",
      "## Claude Code Token Tracking",
      "For Claude Code users, CCDash provides specialized tracking of token consumption across all sessions. It monitors API calls in real-time capturing input/output token counts, tracks cumulative usage per session and across all sessions, and maintains historical token consumption trends over days, weeks, and months. The cost estimator multiplies token counts by current API pricing for Anthropic's tier structure, showing both session-specific and monthly total costs, projecting future costs based on current usage patterns, and alerting when approaching budget thresholds.",
      "Token usage insights identify which operations consume the most tokens through heatmaps showing token usage by hour of day, breakdowns by operation type (code generation, refactoring, testing), and comparisons across different Claude models (Opus vs Sonnet vs Haiku). These insights help developers optimize prompts to reduce token usage, choose appropriate models for different tasks, and identify token-heavy workflows that might benefit from alternative approaches.",
      "Context window management displays current context utilization percentages, warns when conversations approach max context limits, and suggests when to start fresh sessions to avoid degraded performance. For large codebases where context management is critical, these warnings prevent wasted API calls on conversations that will fail due to context overflow. The session analyzer shows which files and conversations are consuming context, helping you trim unnecessary context to fit within limits.",
      "## Tmux Session Management",
      "The tmux integration provides centralized control over terminal multiplexer sessions. The session browser lists all active tmux sessions with window and pane counts, shows session creation times and activity indicators, and allows quick switching between sessions without typing tmux commands. Session health monitoring tracks unresponsive panes that might be hung, identifies zombie processes still holding panes, and detects sessions you've forgotten about consuming resources.",
      "From within CCDash you can create new tmux sessions with templated configurations, attach to existing sessions seamlessly, send commands to specific panes in other sessions, and kill hung sessions or individual panes. The pane viewer shows a tree structure of sessions ‚Üí windows ‚Üí panes with process information and current working directory for each pane. This bird's-eye view of your terminal ecosystem helps manage complex multi-session development environments.",
      "Pre-configured layouts enable one-click setup of common development environments like frontend (editor + build watcher + dev server), backend (editor + API server + database client), full-stack (all of the above in a organized layout), or custom layouts saved from previous sessions. These layouts eliminate the tedium of manually setting up the same terminal arrangement for each project.",
      "## Extensibility and Integration",
      "Built with Python's rich library ecosystem using libraries like 'rich' for beautiful terminal rendering, 'psutil' for cross-platform system metrics, 'prometheus_client' for metrics export, and 'libtmux' for tmux integration. The plugin architecture allows extending functionality without modifying core code. Community plugins add git repository status monitoring, Docker container management, Kubernetes pod watching, custom API endpoint polling, and integration with monitoring services like DataDog or Grafana.",
      "Metrics export supports multiple formats including Prometheus exposition format for scraping by monitoring systems, JSON over HTTP for custom integrations, StatsD protocol for time-series databases, and CSV exports for offline analysis. This makes CCDash suitable not just for interactive monitoring but as a metrics collector in larger observability stacks. The exported data can feed into alerting systems, drive long-term capacity planning, or provide audit trails for infrastructure usage.",
      "The scriptable API enables automation of common tasks through Python scripts that query current metrics, execute actions like session management, configure dashboard layouts programmatically, and schedule metric collection. The API supports both synchronous calls for one-off scripts and async/await patterns for long-running automations. Example scripts in the repository demonstrate automated cleanup of zombie sessions, cost optimization by scheduling intensive workloads during off-peak hours, and alerting integrations that send Slack notifications when resource usage spikes.",
      "## Performance and Resource Efficiency",
      "CCDash is designed to be lightweight and fast, consuming minimal system resources even while continuously monitoring. It achieves <1% CPU usage during normal operation, <50MB RAM footprint (less than most electron apps), and efficient I/O through batch metric collection. The rendering engine only updates changed sections of the terminal using dirty region tracking, updates at configurable refresh rates to balance freshness with resource usage, and pauses updates when the terminal is not visible to save even more resources.",
      "Cross-platform support works seamlessly on Linux with full feature set including temperature monitoring and detailed I/O stats, macOS with complete functionality using native APIs, and Windows via WSL with most features available (native Windows support in development). The consistent experience across platforms lets developers maintain the same workflow whether on local machines, remote servers, or different operating systems.",
      "## Remote Server Monitoring",
      "For managing multiple remote servers, CCDash supports SSH tunneling to monitor remote machines, aggregate views combining metrics from multiple hosts, and synchronized dashboards showing all servers simultaneously. The split-pane layout displays multiple servers side-by-side with color-coded health indicators, synchronized scrolling across hosts, and quick navigation between machines. This is invaluable for managing distributed development environments, monitoring production servers from your laptop, or overseeing infrastructure health across a fleet of machines.",
      "The connection manager remembers SSH credentials securely in the system keychain, supports jump hosts and bastion servers for accessing internal networks, and maintains persistent connections with automatic reconnection on network interruptions. When a connection drops, CCDash shows cached historical data until reconnection succeeds, preventing you from losing context due to transient network issues."
    ],
    "tech": [
      "Python",
      "TUI",
      "Monitoring",
      "Rich Library"
    ],
    "github": "https://github.com/jedarden/ccdash",
    "demo": null,
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <rect x=\"30\" y=\"50\" width=\"140\" height=\"100\" rx=\"6\" fill=\"#8B1A1A\"/>\n                <rect x=\"38\" y=\"58\" width=\"124\" height=\"84\" rx=\"3\" fill=\"white\"/>\n                <text x=\"48\" y=\"78\" font-family=\"monospace\" font-size=\"11\" fill=\"#8B1A1A\">$ stats</text>\n                <rect x=\"48\" y=\"84\" width=\"80\" height=\"5\" rx=\"2\" fill=\"#A52A2A\"/>\n                <rect x=\"48\" y=\"93\" width=\"60\" height=\"5\" rx=\"2\" fill=\"#B8534E\"/>\n                <rect x=\"48\" y=\"102\" width=\"95\" height=\"5\" rx=\"2\" fill=\"#8B1A1A\"/>\n                <text x=\"48\" y=\"120\" font-family=\"monospace\" font-size=\"10\" fill=\"#A52A2A\">CPU: 45%</text>\n                <text x=\"48\" y=\"132\" font-family=\"monospace\" font-size=\"10\" fill=\"#A52A2A\">MEM: 8.2G</text>\n            </svg>",
    "visual": "<div class=\"project-visual visual-ccdash\"><div class=\"tui-header\"><span class=\"tui-title\">CCDash v1.2.0</span><span class=\"tui-time\">12:34:56</span></div><div class=\"tui-panels\"><div class=\"tui-panel\"><div class=\"panel-label\">CPU Usage</div><div class=\"cpu-graph\"><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div><div class=\"cpu-bar\"></div></div></div><div class=\"tui-panel\"><div class=\"panel-label\">Memory</div><div class=\"memory-ring\"></div></div><div class=\"tui-panel\"><div class=\"panel-label\">Tokens</div><div class=\"token-counter\">847K</div><div class=\"token-label\">Today's Usage</div></div><div class=\"tui-panel\"><div class=\"panel-label\">Sessions</div><div class=\"tmux-sessions\"><div class=\"tmux-session\"><span class=\"session-dot active\"></span>main</div><div class=\"tmux-session\"><span class=\"session-dot\"></span>build</div><div class=\"tmux-session\"><span class=\"session-dot active\"></span>test</div></div></div></div><div class=\"ccdash-corner-icon\"><svg viewBox=\"0 0 40 40\"><rect x=\"4\" y=\"8\" width=\"32\" height=\"24\" rx=\"2\" fill=\"#8B1A1A\"/><rect x=\"6\" y=\"10\" width=\"28\" height=\"20\" rx=\"1\" fill=\"white\"/><text x=\"10\" y=\"18\" font-family=\"monospace\" font-size=\"5\" fill=\"#8B1A1A\">$</text></svg></div></div>",
    "tldr": "A terminal dashboard that monitors system resources, Claude Code token usage, and tmux sessions in one unified TUI. Real-time graphs for CPU, memory, and network alongside session management tools for developers who live in the terminal."
  },
  {
    "id": "face",
    "name": "Face Detection",
    "tagline": "Real-Time Face Recognition System",
    "description": [
      "This comprehensive face detection system delivers production-ready real-time facial recognition using face-api.js and TensorFlow.js. It runs entirely in the browser, providing instant face detection, landmark identification, and facial expression analysis without requiring server-side processing or compromising user privacy. The client-side architecture means sensitive biometric data never leaves the user's device, making it ideal for privacy-sensitive applications and GDPR-compliant deployments.",
      "## Core Capabilities",
      "The system detects multiple faces simultaneously in real-time video streams or static images, with no practical limit on the number of faces processed per frame. For each detected face, it identifies 68 facial landmarks with sub-pixel accuracy‚Äîpoints marking eyes, eyebrows, nose, mouth, and jaw contours. These landmarks enable precise face alignment, 3D head pose estimation, and detailed facial geometry analysis. The system estimates age within a 5-year range and determines gender with over 95% accuracy across diverse demographics.",
      "Expression recognition goes beyond simple smile detection, classifying seven distinct emotional states: happy, sad, surprised, neutral, angry, fearful, and disgusted. The system outputs confidence scores for each emotion, allowing nuanced interpretation of mixed or subtle expressions. This multi-label classification means it can detect complex emotional states like 'slightly happy but mostly neutral' or 'surprised and fearful simultaneously.'",
      "Face recognition functionality enables identity verification by comparing detected faces against a database of known individuals. The system generates 128-dimensional face descriptors (embeddings) that capture unique facial characteristics while remaining compact for efficient storage and comparison. Matching uses Euclidean distance in embedding space, with configurable similarity thresholds to balance false positive and false negative rates based on your security requirements.",
      "## Performance & Optimization",
      "All processing happens client-side using WebGL-accelerated neural networks, achieving smooth 30+ FPS frame rates even on mid-range mobile devices. The system intelligently uses WebGL for GPU acceleration when available, falling back to CPU-based computation on older devices while maintaining acceptable performance. Memory usage is carefully managed through frame pooling and efficient tensor operations, preventing the memory leaks common in client-side ML applications.",
      "Three model variants are available to balance accuracy and speed: the Tiny models prioritize real-time performance for resource-constrained devices, delivering 60+ FPS with slightly reduced accuracy. Standard models provide an optimal balance for most use cases, maintaining high accuracy at 30 FPS on typical hardware. High-accuracy models maximize detection quality for scenarios where precision matters more than speed, such as photo analysis or forensic applications.",
      "The inference pipeline is optimized with several techniques: input image scaling reduces computation for distant faces while maintaining quality for close-ups, region-of-interest tracking minimizes redundant processing by focusing on areas where faces are likely to appear, and temporal smoothing across video frames reduces jitter and improves landmark stability. These optimizations combine to deliver production-grade performance without requiring expensive hardware.",
      "## Privacy-First Architecture",
      "By processing everything in the browser, the system ensures biometric data never leaves the user's device. This eliminates server-side storage of facial data, prevents potential data breaches or unauthorized access, satisfies GDPR right-to-be-forgotten requirements automatically (data only exists in browser memory), and allows offline operation without network connectivity. For privacy-sensitive applications like healthcare, education, or consumer products, this architecture provides robust security guarantees that server-based systems cannot match.",
      "The system includes privacy controls allowing users to see exactly what data is being captured, delete their face descriptors at any time, and opt out of recognition features while still using basic detection. Transparency is built in‚Äîthe code is open source, auditable, and contains no telemetry or hidden data collection. This makes it suitable for applications in regions with strict privacy regulations or privacy-conscious user bases.",
      "## Production Deployment",
      "Built with a focus on both research and production use, the repository includes comprehensive documentation covering API usage, integration patterns, and troubleshooting guides. Docker deployment configurations enable easy scaling across multiple instances, with load balancing support for high-traffic applications. Performance optimization guides help developers tune the system for their specific use cases, covering topics like model selection, hardware acceleration, and batch processing strategies.",
      "The system has been tested across various lighting conditions from bright sunlight to low-light indoor environments, camera angles including extreme pitch and yaw, and demographic groups to ensure robust detection across age, gender, and ethnicity. Benchmark results demonstrate >98% detection accuracy on standard face datasets, with particularly strong performance on challenging scenarios like partially occluded faces or profile views.",
      "## Real-World Applications",
      "Attendance systems use the technology to automate check-ins without physical contact, speeding up entry processes while maintaining accurate records. The system can handle crowded environments with dozens of faces in frame, matching each against employee databases in milliseconds. Integration with access control systems enables touchless door unlocking, time tracking, and occupancy monitoring.",
      "Security applications leverage continuous monitoring capabilities to detect unauthorized individuals, track movement patterns across camera views, and alert on suspicious behavior combined with expression analysis. The multi-face detection enables crowd monitoring, while the landmark tracking can identify individuals attempting to obscure their faces or use disguises.",
      "Photo organization tools use the face recognition to automatically tag people in personal photo collections, create albums grouped by person, and find all photos of specific individuals across years of digital archives. The client-side processing means users' family photos never need to be uploaded to third-party servers, addressing a major privacy concern with cloud-based photo services."
    ],
    "tech": [
      "TensorFlow.js",
      "face-api.js",
      "WebGL",
      "Docker"
    ],
    "github": "https://face.jedarden.com",
    "demo": "https://face.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <circle cx=\"100\" cy=\"100\" r=\"60\" fill=\"none\" stroke=\"#8B1A1A\" stroke-width=\"3\"/>\n                <circle cx=\"80\" cy=\"85\" r=\"8\" fill=\"#A52A2A\"/>\n                <circle cx=\"120\" cy=\"85\" r=\"8\" fill=\"#A52A2A\"/>\n                <path d=\"M75 120 Q100 135 125 120\" stroke=\"#B8534E\" stroke-width=\"3\" fill=\"none\" stroke-linecap=\"round\"/>\n                <rect x=\"60\" y=\"75\" width=\"30\" height=\"3\" fill=\"#8B1A1A\" opacity=\"0.6\"/>\n                <rect x=\"110\" y=\"75\" width=\"30\" height=\"3\" fill=\"#8B1A1A\" opacity=\"0.6\"/>\n                <circle cx=\"70\" cy=\"50\" r=\"3\" fill=\"#A52A2A\"/>\n                <circle cx=\"130\" cy=\"50\" r=\"3\" fill=\"#A52A2A\"/>\n                <circle cx=\"50\" cy=\"100\" r=\"3\" fill=\"#A52A2A\"/>\n                <circle cx=\"150\" cy=\"100\" r=\"3\" fill=\"#A52A2A\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-face\">\n                            <div class=\"face-outline\">\n                                <div class=\"scan-line\"></div>\n                                <div class=\"detection-point\"></div>\n                                <div class=\"detection-point\"></div>\n                                <div class=\"detection-point\"></div>\n                            </div>\n                        </div>",
    "tldr": "Browser-based face detection using TensorFlow.js‚Äîno server required. Detects multiple faces in real-time, identifies 68 facial landmarks, estimates age and gender, and recognizes expressions. All processing happens client-side for complete privacy."
  },
  {
    "id": "gait",
    "name": "Gait Analysis",
    "tagline": "Real-Time Human Pose & Motion Tracking",
    "description": [
      "This advanced pose detection system leverages TensorFlow.js to perform real-time human pose estimation and gait analysis directly in the browser. It tracks 17 key body points including joints, estimates 3D positioning, and analyzes movement patterns to provide insights into walking patterns, posture, and biomechanics‚Äîall without requiring specialized hardware. Running entirely client-side, the system democratizes motion analysis technology that previously required expensive lab equipment and specialized expertise.",
      "## Real-Time Pose Tracking",
      "The system detects and tracks multiple people simultaneously in video streams, identifying 17 anatomical keypoints per person: ankles, knees, hips, shoulders, elbows, wrists, eyes, ears, and nose. Each keypoint comes with a confidence score indicating detection reliability, allowing the system to filter unreliable data and maintain accuracy even with partial occlusions or challenging camera angles. The tracking algorithm maintains identity across frames, preventing confusion when multiple people cross paths or temporarily leave the frame.",
      "Joint angle calculations provide precise measurements of flexion, extension, and rotation at major joints. The system computes knee angles during squats to ensure proper form, shoulder angles during overhead presses to prevent injury, and hip angles during deadlifts to maintain safe spinal positioning. These real-time measurements enable immediate feedback‚Äîcritical for coaching applications where correcting form before it becomes habitual prevents injuries and accelerates skill development.",
      "Movement velocity analysis tracks how quickly different body parts move through space, identifying compensation patterns where one side moves faster than the other, detecting explosive power output during jumps or sprints, and measuring deceleration control during landing phases. This data is invaluable for athletic training, where subtle asymmetries often predict injury risk or indicate areas needing strengthening.",
      "## Gait Analysis Capabilities",
      "Gait analysis functionality measures stride length by tracking the distance between heel strikes, calculates cadence by counting steps per minute, identifies gait abnormalities like limping or uneven weight distribution, and detects deviations from normal walking patterns that may indicate injury or neurological issues. The system can differentiate between intentional movement variations and problematic compensations, using machine learning models trained on extensive biomechanics datasets.",
      "For physical therapy applications, the system tracks patient recovery by comparing current gait patterns against baseline measurements taken before injury or at the start of treatment. Progress visualizations show improvements in symmetry, stride consistency, and range of motion over weeks or months. Therapists can set specific goals‚Äîlike achieving 90% symmetry in step length‚Äîand the system automatically monitors progress toward those targets, providing objective data to complement clinical assessments.",
      "The 3D pose estimation extends beyond 2D keypoint detection, inferring depth information to estimate true 3D positions of body parts. While running from a single camera (unlike expensive multi-camera motion capture systems), the system uses learned priors about human body proportions and movement constraints to reconstruct plausible 3D poses. This enables analysis of forward/backward lean, rotation around the vertical axis, and depth-based measurements that 2D systems cannot capture.",
      "## Performance Optimization",
      "Optimized for both accuracy and performance, the system runs smoothly at 30+ FPS on modern devices while maintaining high-quality pose estimations. On high-end hardware, it can achieve 60+ FPS for ultra-smooth tracking, while on mobile devices it gracefully degrades to 15-20 FPS while maintaining accuracy. The adaptive performance scaling ensures the system remains usable across a wide range of devices, from flagship smartphones to budget laptops.",
      "Multiple model variants offer different performance profiles: the MobileNet-based models prioritize speed for real-time applications, achieving 60 FPS on mid-range hardware with acceptable accuracy for most use cases. ResNet-based models deliver higher accuracy at the cost of performance, ideal for detailed analysis where precision matters more than frame rate. The system can dynamically switch models based on device capabilities or user preferences.",
      "## Visualization and Analysis Tools",
      "The system includes comprehensive visualization tools that overlay skeletal structures on video feeds, showing detected keypoints as colored dots, connecting them with lines to form a stick figure representation, and highlighting joints with angle measurements when relevant. Color coding indicates confidence levels‚Äîgreen for high-confidence detections, yellow for moderate confidence, red for low confidence‚Äîallowing users to quickly assess tracking quality.",
      "Historical tracking captures movement patterns over time, storing pose sequences for playback and analysis. Side-by-side comparison views let therapists show patients their current form versus target form, or athletes compare their technique against professional demonstrations. The timeline scrubber allows frame-by-frame analysis of critical movement phases, like the transition from eccentric to concentric muscle contraction during a squat.",
      "Export capabilities generate detailed biomechanical reports in CSV, JSON, or PDF formats, including joint angle time series, velocity profiles, and statistical summaries. These exports integrate with research workflows, enabling scientists to process the data in tools like MATLAB or Python for advanced statistical analysis. For clinical applications, the reports provide documentation for insurance claims or medical records.",
      "## Real-World Applications",
      "Fitness trainers use the system to provide real-time form feedback during remote coaching sessions, ensuring clients perform exercises correctly even without in-person supervision. The system can trigger audio cues when form degrades‚Äî'knees tracking over toes' during squats or 'keep your back straight' during deadlifts‚Äîproviding coaching at scale that would be impossible to deliver manually.",
      "Physical therapists track patient recovery with objective metrics, moving beyond subjective assessments to quantifiable improvements. Post-surgery knee rehabilitation can be monitored by tracking range of motion increases week over week. Balance training can be quantified by measuring center of mass stability during single-leg stands. This objective data helps justify continued treatment to insurance providers and gives patients concrete evidence of their progress.",
      "Sports performance analysts use the system to optimize running form, reducing injury risk and improving efficiency. Analyzing sprinters' acceleration phases reveals power output asymmetries or suboptimal joint angles. Distance runners can be coached toward more economical movement patterns that reduce energy expenditure. The system has been used by Olympic training programs to fine-tune technique in everything from swimming to gymnastics, providing insights that previously required expensive lab visits.",
      "Ergonomic assessments in workplace settings identify risky movement patterns before they cause repetitive strain injuries. The system can monitor warehouse workers performing lifting tasks, office workers at their desks, or assembly line workers doing repetitive motions. By detecting awkward postures, excessive force application, or high-frequency repetitive movements, the system helps companies proactively address ergonomic risks, reducing workers' compensation claims and improving employee wellbeing."
    ],
    "tech": [
      "TensorFlow.js",
      "PoseNet",
      "Computer Vision",
      "WebGL"
    ],
    "github": "https://gait.jedarden.com",
    "demo": "https://gait.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <circle cx=\"100\" cy=\"35\" r=\"20\" fill=\"#8B1A1A\" stroke=\"white\" stroke-width=\"3\"/>\n                <circle cx=\"94\" cy=\"32\" r=\"3\" fill=\"white\"/>\n                <circle cx=\"106\" cy=\"32\" r=\"3\" fill=\"white\"/>\n                <path d=\"M92 40 Q100 46 108 40\" stroke=\"white\" stroke-width=\"2\" fill=\"none\"/>\n                <line x1=\"100\" y1=\"55\" x2=\"100\" y2=\"110\" stroke=\"#8B1A1A\" stroke-width=\"6\" stroke-linecap=\"round\"/>\n                <line x1=\"100\" y1=\"70\" x2=\"65\" y2=\"55\" stroke=\"#A52A2A\" stroke-width=\"5\" stroke-linecap=\"round\"/>\n                <line x1=\"65\" y1=\"55\" x2=\"50\" y2=\"35\" stroke=\"#A52A2A\" stroke-width=\"5\" stroke-linecap=\"round\"/>\n                <circle cx=\"50\" cy=\"35\" r=\"6\" fill=\"#B8534E\"/>\n                <line x1=\"100\" y1=\"70\" x2=\"135\" y2=\"90\" stroke=\"#A52A2A\" stroke-width=\"5\" stroke-linecap=\"round\"/>\n                <line x1=\"100\" y1=\"110\" x2=\"80\" y2=\"160\" stroke=\"#8B1A1A\" stroke-width=\"5\" stroke-linecap=\"round\"/>\n                <line x1=\"100\" y1=\"110\" x2=\"120\" y2=\"160\" stroke=\"#8B1A1A\" stroke-width=\"5\" stroke-linecap=\"round\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-gait\"><svg class=\"skeleton-figure\" viewBox=\"0 0 80 160\"><defs><clipPath id=\"headClip\"><circle cx=\"40\" cy=\"20\" r=\"14\"/></clipPath></defs><image href=\"logo.jpg\" x=\"26\" y=\"6\" width=\"28\" height=\"28\" clip-path=\"url(#headClip)\" preserveAspectRatio=\"xMidYMid slice\"/><circle cx=\"40\" cy=\"20\" r=\"14\" fill=\"none\" stroke=\"white\" stroke-width=\"2\"/><line x1=\"40\" y1=\"34\" x2=\"40\" y2=\"80\" stroke=\"#8B1A1A\" stroke-width=\"4\"/><g class=\"gait-waving-arm\"><line x1=\"40\" y1=\"50\" x2=\"20\" y2=\"35\" stroke=\"#A52A2A\" stroke-width=\"3\"/><circle cx=\"20\" cy=\"35\" r=\"4\" fill=\"#B8534E\"/></g><line x1=\"40\" y1=\"50\" x2=\"60\" y2=\"70\" stroke=\"#A52A2A\" stroke-width=\"3\"/><line x1=\"40\" y1=\"80\" x2=\"25\" y2=\"120\" stroke=\"#8B1A1A\" stroke-width=\"3\"/><line x1=\"40\" y1=\"80\" x2=\"55\" y2=\"120\" stroke=\"#8B1A1A\" stroke-width=\"3\"/></svg></div>",
    "tldr": "Real-time pose estimation and gait analysis that tracks 17 body keypoints from webcam video. Measures joint angles, stride patterns, and movement asymmetries for applications in physical therapy, sports coaching, and ergonomic assessment."
  },
  {
    "id": "asteroid",
    "name": "Asteroid",
    "tagline": "Physics-Based Space Simulation",
    "description": [
      "An immersive browser-based space simulation that combines classic arcade gameplay with realistic orbital mechanics. Players navigate through procedurally generated asteroid fields, managing momentum, gravitational forces, and resource constraints while exploring the physics of space travel in an engaging, educational format. Unlike abstracted space games that use airplane-like controls, Asteroid simulates actual spacecraft maneuvering where every action has an equal and opposite reaction, thrust only changes velocity not direction, and orbital mechanics dominate strategic decision-making.",
      "## Realistic Physics Simulation",
      "The simulation implements Newtonian physics with accurate momentum conservation, ensuring the spacecraft follows the laws of motion that govern real space travel. Thrust in any direction changes velocity by a precise amount based on engine power and spacecraft mass. Without thrust, the ship continues in a straight line at constant velocity indefinitely‚Äîthere's no drag to slow it down. This fundamental difference from atmospheric flight creates a unique control challenge where planning ahead is essential.",
      "Gravitational attraction between celestial bodies follows the inverse-square law, pulling objects toward massive bodies with force proportional to mass and inversely proportional to distance squared. Large asteroids exert noticeable gravitational pull, bending trajectories and enabling slingshot maneuvers. Players can use gravity assists to change direction without expending fuel, execute Hohmann transfer orbits to efficiently match velocities with targets, and even establish stable orbits around massive objects‚Äîall using the same physics that govern real spacecraft.",
      "Collision detection uses accurate bounding geometries rather than simple circle collisions, accounting for asteroid rotation and irregular shapes. The physics engine calculates impact vectors, transfers momentum realistically during collisions, and applies angular momentum from off-center impacts. A glancing blow imparts less energy transfer than a head-on collision, and hitting an asteroid off-center causes it to spin. These details make the physics feel authentic rather than gamey.",
      "## Procedural Generation System",
      "The procedural generation ensures each playthrough offers unique challenges and discoveries. Asteroid fields are generated using Perlin noise for natural-looking clustering, balancing dense dangerous regions with clear navigation corridors. Field density increases gradually as players progress, introducing new obstacles without overwhelming beginners. Asteroid sizes follow a power-law distribution similar to real debris fields, with many small rocks and occasional massive planetoids.",
      "Resource placement uses strategic positioning algorithms, placing fuel depots near difficult navigation sections where players likely need replenishment, scattering power-ups at varying distances to encourage exploration, and hiding rare collectibles in hard-to-reach areas requiring advanced maneuvering skills. The distribution creates risk-reward decisions: do you detour for resources or take the direct but fuel-limited route?",
      "Gravitational bodies appear semi-randomly with constraints ensuring playable configurations. Massive objects never spawn too close together where their combined gravity creates inescapable wells. Slingshot opportunities appear regularly enough to reward players who've mastered orbital mechanics. The generation algorithm ensures every level is completable while still presenting significant challenge.",
      "## Progressive Gameplay and Learning",
      "Unlike traditional arcade games where movement is trivial and dodging is the only skill, Asteroid's controls require understanding momentum physics. New players initially struggle with the counter-intuitive controls: thrusting forward doesn't make you go forward if you were already moving sideways. But this difficulty is the point‚Äîmastering the controls means internalizing Newtonian mechanics in a way that reading about it never achieves.",
      "The learning curve is carefully designed through progressive difficulty scaling. Early levels have widely-spaced asteroids and weak gravity, allowing players to learn basic thrust vectoring. Mid-game levels introduce tighter spaces requiring precision maneuvering and planning ahead. Late game challenges include navigating between close gravitational bodies, executing complex orbital insertions, and managing resources during extended missions. Each new mechanic is introduced through gameplay rather than tutorials, following the 'easy to learn, hard to master' design philosophy.",
      "Achievement systems provide concrete goals beyond simple survival: execute a clean gravity assist without thrusting, collect all resources in a level without colliding with anything, complete a level using minimal fuel consumption, reach maximum velocity, or establish a stable orbit. These achievements encourage players to experiment with advanced techniques and develop true mastery of the physics.",
      "## Performance and Technical Excellence",
      "Built with HTML5 Canvas and highly optimized JavaScript, the game runs smoothly at 60 FPS while simulating dozens of objects with full physics calculations every frame. The physics engine uses Verlet integration for numerical stability, spatial partitioning to avoid O(n¬≤) collision checks, and object pooling to eliminate garbage collection pauses during gameplay. These optimizations ensure butter-smooth framerates even on lower-end devices or when dozens of asteroids fill the screen.",
      "The rendering pipeline is carefully optimized with frustum culling to skip drawing off-screen objects, dirty rectangle tracking to minimize canvas redraws, and sprite batching to reduce draw calls. Background stars use parallax scrolling at multiple depths to create convincing depth illusion without expensive 3D rendering. Particle effects for thrust plumes and collision debris are lightweight yet visually impressive, using simple math tricks rather than heavy physics simulation.",
      "Touch and keyboard controls are equally responsive, with adaptive control sensitivity based on input device. Keyboard players get precise digital input with customizable thrust magnitudes. Touch players get virtual joystick controls with haptic feedback on mobile devices. Gamepad support detects Xbox and PlayStation controllers, mapping analog sticks to thrust vectors and triggers to rotation. This cross-platform input handling makes the game accessible regardless of device.",
      "## Educational Features",
      "Educational overlays explain the physics principles in action without interrupting gameplay. Velocity vectors show current speed and direction, making it clear that ships have momentum even when not thrusting. Orbital path predictions display the trajectory the ship will follow if no further thrust is applied, teaching players to think ahead. Force vectors illustrate gravitational pulls from nearby massive objects, making invisible forces visible and understandable.",
      "Physics tooltips appear contextually: when approaching a gravitational body, the overlay explains slingshot maneuvers and Oberth effect. When fuel runs low, it discusses delta-v budgets and efficient maneuvering. When achieving stable orbit, it explains orbital parameters like apoapsis and periapsis. These just-in-time lessons connect abstract concepts to immediate gameplay situations, cementing understanding through practical application.",
      "Comparison modes let players toggle between the realistic physics and an 'arcade mode' with simplified controls, dramatically illustrating how real space travel differs from science fiction depictions. Switching between modes makes it viscerally clear why spacecraft can't just turn around and fly back the way they came, why orbital maneuvering requires patience and planning, and why fuel is the limiting resource in space missions.",
      "## Accessibility and Engagement",
      "Whether you're a space enthusiast learning orbital mechanics, a physics student building intuition for classical mechanics, or a casual gamer looking for a unique challenge, Asteroid offers an entertaining way to build understanding of how objects move in space. The game doesn't compromise on physical accuracy‚Äîno atmosphere, no friction, no magic forces keeping you oriented 'up.' What you learn in this game applies to real spacecraft maneuvering, making it not just fun but genuinely educational in a way that most games aren't. Players report that after mastering Asteroid, they understand Kerbal Space Program tutorials immediately and can follow SpaceX mission profiles with newfound comprehension of the orbital mechanics at play."
    ],
    "tech": [
      "JavaScript",
      "Canvas",
      "Physics Engine",
      "Game Development"
    ],
    "github": null,
    "demo": "https://asteroid.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <polygon points=\"100,30 130,70 160,65 140,100 165,135 125,130 100,170 75,130 35,135 60,100 40,65 70,70\"\n                         fill=\"#86868B\" stroke=\"#1D1D1F\" stroke-width=\"2\"/>\n                <circle cx=\"90\" cy=\"70\" r=\"8\" fill=\"#5A5A5F\"/>\n                <circle cx=\"120\" cy=\"90\" r=\"6\" fill=\"#5A5A5F\"/>\n                <circle cx=\"100\" cy=\"120\" r=\"10\" fill=\"#5A5A5F\"/>\n                <polygon points=\"180,40 185,45 180,50 175,45\" fill=\"#B8534E\"/>\n                <line x1=\"180\" y1=\"40\" x2=\"165\" y2=\"55\" stroke=\"#B8534E\" stroke-width=\"2\"/>\n                <circle cx=\"50\" cy=\"50\" r=\"3\" fill=\"white\" opacity=\"0.6\"/>\n                <circle cx=\"150\" cy=\"40\" r=\"2\" fill=\"white\" opacity=\"0.6\"/>\n                <circle cx=\"160\" cy=\"150\" r=\"2.5\" fill=\"white\" opacity=\"0.6\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-asteroid\">\n                            <div class=\"stars\">\n                                <div class=\"star\" style=\"top: 20%; left: 30%;\"></div>\n                                <div class=\"star\" style=\"top: 40%; left: 60%;\"></div>\n                                <div class=\"star\" style=\"top: 70%; left: 20%;\"></div>\n                            </div>\n                            <div class=\"asteroid\"></div>\n                            <div class=\"asteroid\"></div>\n                        </div>",
    "tldr": "A physics-based asteroid simulation with realistic orbital mechanics, gravitational interactions, and collision detection. Built with WebGL for smooth rendering of thousands of objects following Newtonian dynamics in real-time."
  },
  {
    "id": "sunsim",
    "name": "Sun Simulator",
    "tagline": "Interactive Sun Position Visualization",
    "description": [
      "The Sun Simulator is a sophisticated web application that visualizes solar position throughout the day and across seasons with stunning accuracy. It combines astronomical calculations with an intuitive compass rose interface to help photographers, architects, solar installers, and outdoor enthusiasts understand exactly where the sun will be at any given time and location. The interactive map-based interface makes celestial mechanics accessible to everyone, transforming complex astronomical data into intuitive visualizations.",
      "## Astronomical Precision",
      "The application calculates solar azimuth and elevation using precise astronomical algorithms based on Jean Meeus's implementations, accounting for your exact latitude and longitude down to the meter. It factors in atmospheric refraction, the equation of time, solar declination variations, and even the slight differences caused by Earth's elliptical orbit. Users can scrub through time to see how sunlight angles change throughout the day, compare different seasons with solstice and equinox presets, and identify optimal times for solar exposure or shade with minute-by-minute precision.",
      "The compass rose visualization makes it immediately clear which direction the sun rises and sets from any location on Earth, with precise azimuth readings overlaid on an interactive map powered by Leaflet. The sun path arc shows the entire trajectory across the sky, with markers for sunrise, solar noon, and sunset. Color-coded zones indicate golden hour periods, blue hour transitions, and civil/nautical/astronomical twilight phases‚Äîcritical information for photographers planning shoots.",
      "## Interactive Features",
      "Built with modern web technologies including Canvas for high-performance rendering, the simulator features smooth 60fps animations, responsive touch controls optimized for mobile devices, and real-time calculations that update instantaneously as you adjust location or time parameters. The timeline scrubber allows you to play through an entire day's sun movement in seconds, or advance frame-by-frame for precise analysis. Date controls let you jump to solstices, equinoxes, or any arbitrary date to compare seasonal variations.",
      "The location picker integrates with browser geolocation for instant positioning, or accepts manual coordinate input for planning trips to unfamiliar locations. Search functionality powered by geocoding APIs lets you enter city names, addresses, or landmarks. The map layer supports multiple basemaps‚Äîsatellite imagery, topographical maps, or street views‚Äîgiving context to the sun's position relative to local terrain and structures.",
      "## Professional Applications",
      "For solar panel installers, the simulator calculates optimal panel angles for maximum energy capture throughout the year, shows shadow patterns cast by nearby buildings or trees, and estimates seasonal energy production variations. The data export feature provides detailed tables of solar angles, sunrise/sunset times, and day length for entire years, enabling precise system sizing and performance predictions.",
      "House hunters find the tool invaluable for evaluating natural lighting in potential homes. Before scheduling a showing, you can visualize exactly how sunlight will move through the property at different times of day and throughout the seasons. Check if that north-facing living room will get any direct sun, whether the backyard will be shaded by the neighbor's house in winter, or if the bedroom will catch harsh morning light. These insights help identify deal-breakers before wasting time on visits.",
      "Architects and building designers use the tool to analyze natural lighting opportunities, plan window placements for passive solar heating, design overhangs for summer shading while allowing winter sun penetration, and ensure compliance with daylight access regulations. The visualization clearly shows how sunlight will enter spaces at different times of day and year, enabling evidence-based design decisions that optimize for energy efficiency and occupant comfort.",
      "Photographers leverage the simulator for planning landscape shots during golden hour, determining when sunlight will illuminate specific features from desired angles, scheduling portrait sessions with optimal natural lighting, and scouting locations remotely before committing to travel. The ability to preview exactly where and when the sun will be eliminates guesswork and ensures you're in the right place at the right time.",
      "## Educational Value",
      "Beyond professional applications, the Sun Simulator serves as an educational tool that makes celestial mechanics intuitive and accessible. Students can observe how Earth's axial tilt causes seasonal variations in sun path, understand why summer days are longer than winter days at different latitudes, and visualize the midnight sun phenomenon in polar regions or equatorial sun patterns near the equator.",
      "The tool demonstrates why solar panels should be tilted differently in different locations, how sundials work and why they need latitude-specific designs, and why buildings in the northern hemisphere have south-facing windows for maximum solar gain while southern hemisphere buildings favor north-facing orientations. These concepts, often abstract in textbooks, become immediately clear through interactive visualization.",
      "## Technical Implementation",
      "The implementation uses SunCalc.js for astronomical calculations, providing sub-degree accuracy across all latitudes and dates. Canvas rendering ensures smooth performance even on older devices, with careful optimization of draw calls and efficient memory management. The responsive design adapts seamlessly from desktop browsers to mobile phones, maintaining full functionality across all screen sizes.",
      "Real-time performance is achieved through incremental calculations‚Äîonly recomputing changed values rather than recalculating everything on each frame. State management keeps the UI snappy even during rapid timeline scrubbing, and Web Workers handle complex calculations off the main thread to prevent UI blocking. The result is a fluid, responsive experience that feels instant despite the mathematical complexity happening behind the scenes."
    ],
    "tech": [
      "JavaScript",
      "Canvas",
      "Astronomy",
      "Geolocation"
    ],
    "github": "https://sunsim.jedarden.com",
    "demo": "https://sunsim.jedarden.com",
    "icon": "<svg class=\"project-icon\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n                <circle cx=\"100\" cy=\"100\" r=\"30\" fill=\"#B8534E\"/>\n                <line x1=\"100\" y1=\"40\" x2=\"100\" y2=\"60\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"100\" y1=\"140\" x2=\"100\" y2=\"160\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"40\" y1=\"100\" x2=\"60\" y2=\"100\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"140\" y1=\"100\" x2=\"160\" y2=\"100\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"55\" y1=\"55\" x2=\"70\" y2=\"70\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"145\" y1=\"145\" x2=\"130\" y2=\"130\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"145\" y1=\"55\" x2=\"130\" y2=\"70\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <line x1=\"55\" y1=\"145\" x2=\"70\" y2=\"130\" stroke=\"#A52A2A\" stroke-width=\"4\" stroke-linecap=\"round\"/>\n                <circle cx=\"100\" cy=\"160\" r=\"5\" fill=\"#8B1A1A\"/>\n                <path d=\"M60 160 Q100 140 140 160\" stroke=\"#1D1D1F\" stroke-width=\"2\" fill=\"none\" opacity=\"0.3\"/>\n            </svg>",
    "visual": "<div class=\"project-visual visual-sunsim\">\n                            <div class=\"map-background\"></div>\n                            <svg class=\"sun-arc\" viewBox=\"0 0 400 300\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path class=\"arc-path\" d=\"M 40 250 Q 200 50 360 250\" fill=\"none\" stroke=\"rgba(253, 184, 19, 0.4)\" stroke-width=\"3\" stroke-dasharray=\"5,5\"/>\n                                <circle class=\"sun-marker\" r=\"12\" fill=\"#FDB813\">\n                                    <animateMotion dur=\"8s\" repeatCount=\"indefinite\">\n                                        <mpath href=\"#sunPath\"/>\n                                    </animateMotion>\n                                </circle>\n                                <path id=\"sunPath\" d=\"M 40 250 Q 200 50 360 250\" fill=\"none\"/>\n                            </svg>\n                            <div class=\"compass-rose\">\n                                <div class=\"compass-direction n\">N</div>\n                                <div class=\"compass-direction s\">S</div>\n                                <div class=\"compass-direction e\">E</div>\n                                <div class=\"compass-direction w\">W</div>\n                            </div>\n                            <div class=\"time-indicators\">\n                                <span class=\"time-label sunrise\">üåÖ 6 AM</span>\n                                <span class=\"time-label noon\">‚òÄÔ∏è 12 PM</span>\n                                <span class=\"time-label sunset\">üåá 6 PM</span>\n                            </div>\n                        </div>",
    "tldr": "Interactive solar position calculator that visualizes the sun's path across the sky for any location and date. Shows sunrise, sunset, golden hour, and shadow directions on an intuitive compass interface with animated day progression."
  }
];

// Export for Node.js environments
if (typeof module !== 'undefined' && module.exports) {
  module.exports = projects;
}
